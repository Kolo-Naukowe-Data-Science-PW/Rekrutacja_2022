{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analiza danych -  eksploracja zbioru związanego z tematem E-commerce. Metoda eksploracji jest dowolna, oceniany jest tylko efekt końcowy. \n",
    "* Zadanie programistyczne - zaimplementuj w języku Python/R algorytm do znajdywania najkrótszej ścieżki w grafie. \n",
    "Przykładowe dane - słownik, gdzie kluczem jest tupla (punkty połączone ze sobą) a wartością odległość między punktami:\n",
    "{\n",
    "  (\"B\", \"D\"): 2,\n",
    "  (\"D\", \"A\"): 1,\n",
    "  (\"B\", \"A\"): 4,\n",
    "  (\"A\", \"C\"): 2,\n",
    "  (\"B\", \"E\"): 3,\n",
    "  (\"C\", \"D\"): 7,\n",
    "  (\"E\", \"C\"): 3\n",
    "} \n",
    "* Machine learning - na wybranym przez siebie zbiorze danych (mają to być dane tabelaryczne (ustrukturyzowane), a problem ma być klasyfikacyjny) należy stworzyć prosty model machine learningowy wraz z całym procesem przetwarzania danych tj. oczyszczanie, transformacje, kodowanie itd..  Najważniejszym kryterium oceny tego zadania będzie metodyka tworzenia modelu, jakość procesu przetwarzania danych wejściowych oraz podejście do oceny jego jakości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\"\n",
    "DATA_F = \"data\"\n",
    "\n",
    "# returns path to file \"filename\" in data folder\n",
    "def get_df(filename):\n",
    "    return os.path.join(DATA_F, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "\n",
    "os.makedirs(DATA_F, exist_ok = True)\n",
    "\n",
    "response = requests.get(URL)\n",
    "if response.status_code == 200:\n",
    "    open(get_df(\"data.data\"), \"wb\").write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the dataset descriptrion (see https://archive.ics.uci.edu/ml/datasets/Credit+Approval) we \n",
    "know that attributes names and values are encrypted to protect the data, however this doesn't \n",
    "stop us from using them for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       678 non-null    object \n",
      " 1   1       678 non-null    float64\n",
      " 2   2       690 non-null    float64\n",
      " 3   3       684 non-null    object \n",
      " 4   4       684 non-null    object \n",
      " 5   5       681 non-null    object \n",
      " 6   6       681 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    object \n",
      " 13  13      677 non-null    float64\n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    object \n",
      "dtypes: float64(4), int64(2), object(10)\n",
      "memory usage: 86.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# load data into memory\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(get_df(\"data.data\"), header=None, na_values=\"?\")\n",
    "df.info()\n",
    "\n",
    "# specified attributes' names weren't provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing numerical columns: 1, 13\n",
      "Missing categorical columns: 0, 3, 4, 5, 6\n"
     ]
    }
   ],
   "source": [
    "# indexes of attributes that have missing values (target column 15 doesn't need to be excluded\n",
    "# by hand scince it has no missing values)\n",
    "\n",
    "dtypes = df.dtypes[:-1] # here exclude target column\n",
    "\n",
    "missing = df.isna().any()\n",
    "missing = [idx for idx in range(len(missing)) if missing[idx]]\n",
    "\n",
    "missing_num = [idx for idx in missing if dtypes[idx] != \"object\"]\n",
    "missing_cat = [idx for idx in missing if dtypes[idx] == \"object\"]\n",
    "\n",
    "print(\"Missing numerical columns:\", \", \".join([str(idx) for idx in missing_num]))\n",
    "print(\"Missing categorical columns:\", \", \".join([str(idx) for idx in missing_cat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.46</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1     2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.00  u  g  w  v  1.25  t  t   1  f  g  202.0    0  +\n",
       "1  a  58.67  4.46  u  g  q  h  3.04  t  t   6  f  g   43.0  560  +"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>678.0</td>\n",
       "      <td>31.568171</td>\n",
       "      <td>11.957862</td>\n",
       "      <td>13.75</td>\n",
       "      <td>22.6025</td>\n",
       "      <td>28.46</td>\n",
       "      <td>38.2300</td>\n",
       "      <td>80.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690.0</td>\n",
       "      <td>4.758725</td>\n",
       "      <td>4.978163</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.75</td>\n",
       "      <td>7.2075</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>690.0</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.6250</td>\n",
       "      <td>28.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>690.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>4.862940</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>67.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>677.0</td>\n",
       "      <td>184.014771</td>\n",
       "      <td>173.806768</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.0000</td>\n",
       "      <td>160.00</td>\n",
       "      <td>276.0000</td>\n",
       "      <td>2000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>690.0</td>\n",
       "      <td>1017.385507</td>\n",
       "      <td>5210.102598</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>395.5000</td>\n",
       "      <td>100000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count         mean          std    min      25%     50%       75%  \\\n",
       "1   678.0    31.568171    11.957862  13.75  22.6025   28.46   38.2300   \n",
       "2   690.0     4.758725     4.978163   0.00   1.0000    2.75    7.2075   \n",
       "7   690.0     2.223406     3.346513   0.00   0.1650    1.00    2.6250   \n",
       "10  690.0     2.400000     4.862940   0.00   0.0000    0.00    3.0000   \n",
       "13  677.0   184.014771   173.806768   0.00  75.0000  160.00  276.0000   \n",
       "14  690.0  1017.385507  5210.102598   0.00   0.0000    5.00  395.5000   \n",
       "\n",
       "          max  \n",
       "1       80.25  \n",
       "2       28.00  \n",
       "7       28.50  \n",
       "10      67.00  \n",
       "13    2000.00  \n",
       "14  100000.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe numerical data\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>678</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>684</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>684</td>\n",
       "      <td>3</td>\n",
       "      <td>g</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>681</td>\n",
       "      <td>14</td>\n",
       "      <td>c</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>681</td>\n",
       "      <td>9</td>\n",
       "      <td>v</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>690</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>690</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>690</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>690</td>\n",
       "      <td>3</td>\n",
       "      <td>g</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>690</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count unique top freq\n",
       "0    678      2   b  468\n",
       "3    684      3   u  519\n",
       "4    684      3   g  519\n",
       "5    681     14   c  137\n",
       "6    681      9   v  399\n",
       "8    690      2   t  361\n",
       "9    690      2   f  395\n",
       "11   690      2   f  374\n",
       "12   690      3   g  625\n",
       "15   690      2   -  383"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe categorical data\n",
    "df.describe(include=\"O\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((552, 15), (138, 15))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df.to_numpy()[:, :-1], df.to_numpy()[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of categorical and numerical columns indexes\n",
    "\n",
    "cat_idxs = [idx for idx in range(X.shape[1]) if dtypes[idx] == \"object\"]\n",
    "num_idxs = [idx for idx in range(X.shape[1]) if dtypes[idx] != \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing and preparation\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# fill missing values in categorical attributes (with most_frequent value for each attribute)\n",
    "cat_miss_pipeline = ColumnTransformer([\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\"), [cat_idxs.index(idx) for idx in missing_cat])\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "# fill missing values in numeric attributes (with mean value for each attribute)\n",
    "num_miss_pipeline = ColumnTransformer([\n",
    "    (\"impute\", SimpleImputer(strategy=\"mean\"), [num_idxs.index(idx) for idx in missing_num])\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "# scale the numerical attributes\n",
    "num_preprocess_pipeline = Pipeline([\n",
    "    (\"miss\", num_miss_pipeline),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "# we don't know anything about relationships between categorical attributes\n",
    "# so we presume none and encode them with one_hot_encoding\n",
    "# if category is binary encode it as one column\n",
    "cat_preprocess_pipeline = Pipeline([\n",
    "    (\"miss\", cat_miss_pipeline),\n",
    "    (\"encoder\", OneHotEncoder(drop=\"if_binary\", sparse=False))\n",
    "])\n",
    "\n",
    "# combine all of them together\n",
    "X_preparation_pipeline = ColumnTransformer([\n",
    "    (\"cat\", cat_preprocess_pipeline, cat_idxs),\n",
    "    (\"num\", num_preprocess_pipeline, num_idxs)\n",
    "])\n",
    "\n",
    "# encode target into binary\n",
    "y_preparation_pipeline = Pipeline([\n",
    "    (\"encoder\", OneHotEncoder(drop=\"if_binary\", sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess both the training set and the test set\n",
    "\n",
    "X_train = X_preparation_pipeline.fit_transform(X_train)\n",
    "y_train = y_preparation_pipeline.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "\n",
    "X_test = X_preparation_pipeline.transform(X_test)\n",
    "y_test = y_preparation_pipeline.transform(y_test.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((552, 42), (138, 42))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of attributes is much higher\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_b',\n",
       " '1',\n",
       " '2',\n",
       " '3_l',\n",
       " '3_u',\n",
       " '3_y',\n",
       " '4_g',\n",
       " '4_gg',\n",
       " '4_p',\n",
       " '5_aa',\n",
       " '5_c',\n",
       " '5_cc',\n",
       " '5_d',\n",
       " '5_e',\n",
       " '5_ff',\n",
       " '5_i',\n",
       " '5_j',\n",
       " '5_k',\n",
       " '5_m',\n",
       " '5_q',\n",
       " '5_r',\n",
       " '5_w',\n",
       " '5_x',\n",
       " '6_bb',\n",
       " '6_dd',\n",
       " '6_ff',\n",
       " '6_h',\n",
       " '6_j',\n",
       " '6_n',\n",
       " '6_o',\n",
       " '6_v',\n",
       " '6_z',\n",
       " '7',\n",
       " '8_t',\n",
       " '9_t',\n",
       " '10',\n",
       " '11_t',\n",
       " '12_g',\n",
       " '12_p',\n",
       " '12_s',\n",
       " '13',\n",
       " '14']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets display all new column names for validation purposes\n",
    "# based on dataset description we can see that it catched \n",
    "# classes correctly (moreover some of described there values\n",
    "# do not occur in practice)\n",
    "\n",
    "new_names = X_preparation_pipeline.get_feature_names_out()\n",
    "for i in range(len(new_names)):\n",
    "    name = new_names[i]\n",
    "\n",
    "    name = name.split(\"__\")[2][1:]\n",
    "    name = name.split(\"_\")\n",
    "    new_names[i] = [int(name[0]), name[1]] if len(name) > 1 else [int(name[0])]\n",
    "\n",
    "new_names.sort()\n",
    "new_names = [\"_\".join([str(x) for x in name]) for name in new_names]\n",
    "new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_v        -> -0.7358\n",
      "6_z        -> -0.4602\n",
      "13         -> -0.4137\n",
      "12_s       -> -0.3249\n",
      "6_dd       -> -0.2133\n",
      "12_p       -> -0.1952\n",
      "2          -> -0.1934\n",
      "3_u        -> -0.1934\n",
      "5_r        -> -0.192\n",
      "11_t       -> -0.1908\n",
      "5_aa       -> -0.173\n",
      "5_k        -> -0.1495\n",
      "8_t        -> -0.0906\n",
      "6_o        -> -0.0652\n",
      "5_cc       -> -0.0571\n",
      "5_q        -> -0.0553\n",
      "1          -> -0.0491\n",
      "3_y        -> -0.0491\n",
      "7          -> -0.049\n",
      "9_t        -> -0.0479\n",
      "6_h        -> -0.0122\n",
      "6_j        -> -0.0086\n",
      "5_m        -> -0.0086\n",
      "4_p        -> 0.0059\n",
      "5_w        -> 0.0099\n",
      "5_x        -> 0.0203\n",
      "5_j        -> 0.0272\n",
      "0_b        -> 0.0412\n",
      "5_c        -> 0.0645\n",
      "6_n        -> 0.0648\n",
      "5_ff       -> 0.0656\n",
      "6_ff       -> 0.0741\n",
      "4_gg       -> 0.0746\n",
      "12_g       -> 0.0809\n",
      "5_i        -> 0.0979\n",
      "5_e        -> 0.1118\n",
      "10         -> 0.1201\n",
      "5_d        -> 0.1759\n",
      "6_bb       -> 0.1877\n",
      "3_l        -> 0.1987\n",
      "4_g        -> 0.1987\n"
     ]
    }
   ],
   "source": [
    "# lets understand the data a little better\n",
    "\n",
    "train_df = pd.DataFrame(np.c_[X_train, y_train], columns=new_names + [\"target\"])\n",
    "\n",
    "corr = []\n",
    "for name in new_names[:-1]:\n",
    "    corr.append(train_df[\"target\"].corr(train_df[name]))\n",
    "\n",
    "corr_description = list(zip(new_names[:-1], corr))\n",
    "corr_description.sort(key=lambda x: x[1])\n",
    "\n",
    "for name, val in corr_description:\n",
    "    print(f\"{name:10} -> {round(val, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets reduce number of arguments by dropping all of \n",
    "# them which have absolute correlation with target \n",
    "# less than threshold\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Shrinker(BaseEstimator):\n",
    "    def __init__(self, threshold=0.1):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # indexes of attributes  to keep\n",
    "        keep = np.where(abs(np.array(corr)) > self.threshold)[0]\n",
    "\n",
    "        return X[:, keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it\n",
    "shrinker = Shrinker()\n",
    "\n",
    "assert shrinker.transform(X_train).shape[1] == sum(abs(np.array(corr)) > 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another preprocessing step - outlier detection and their removal\n",
    "# here nu parameters will affect number of samples classified as outliers\n",
    "# (the higher the more)\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "class OutliersRemover(BaseEstimator):\n",
    "    def __init__(self, nu=0.01):\n",
    "        self.nu = nu\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.ocsvm = OneClassSVM(nu=self.nu)\n",
    "        self.ocsvm.fit(X)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        y_pred = self.ocsvm.predict(X)\n",
    "\n",
    "        # indexes of rows to keep\n",
    "        keep = np.where(y_pred == 1)[0]\n",
    "        \n",
    "        if y is not None:\n",
    "            return X[keep, :], y[keep]\n",
    "        return X[keep, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it\n",
    "remover = OutliersRemover().fit(X_train)\n",
    "\n",
    "assert remover.transform(X_train).shape != X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's prepare some datasets with removed outliers\n",
    "\n",
    "X_train_small = []\n",
    "y_train_small = []\n",
    "\n",
    "# after cutting more performance might still increase however\n",
    "# it might not generalise better scince we cutted to much data\n",
    "for nu in [0.05, 0.1, 0.15]: \n",
    "    remover = OutliersRemover(nu=nu).fit(X_train)\n",
    "    X_temp, y_temp = remover.transform(X_train, y_train)\n",
    "    X_train_small.append(X_temp)\n",
    "    y_train_small.append(y_temp)\n",
    "\n",
    "# warning: it leads to much greater ram usage in %, however\n",
    "# we can do it scince original dataset is relatively small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4927536231884058"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check baseline performance\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>                      -> 0.8333\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>            -> 0.8406\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>                 -> 0.7971\n",
      "<class 'sklearn.svm._classes.SVC'>                                               -> 0.8406\n",
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>                   -> 0.7971\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>                        -> 0.8623\n"
     ]
    }
   ],
   "source": [
    "# lets experiment with different classifiers on default settings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "for model in [LogisticRegression(), MLPClassifier(), KNeighborsClassifier(), SVC(), AdaBoostClassifier(), RandomForestClassifier()]:\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "\n",
    "    print(f\"{str(model.__class__):80} -> {round(score, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# utility function\n",
    "def search(model, params, use_nu=True, cv=3):\n",
    "    if use_nu:\n",
    "        data = zip([X_train, *X_train_small], [y_train, *y_train_small])\n",
    "    else:\n",
    "        data = zip([X_train], [y_train])\n",
    "\n",
    "    best_model = None\n",
    "    best_score = 0.\n",
    "    best_params = None\n",
    "    best_ds = None\n",
    "\n",
    "    for idx, (X_temp, y_temp) in enumerate(data):\n",
    "        grid = GridSearchCV(model, params, n_jobs=-1, verbose=1, cv=cv)\n",
    "        grid.fit(X_temp, y_temp)\n",
    "        score = grid.score(X_test, y_test)\n",
    "\n",
    "        print(f\"{round(grid.best_score_, 4):>6} -> {round(score, 4):<6}\\n\")\n",
    "\n",
    "        # pick model which generalizes the best\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = grid.best_estimator_\n",
    "            best_params = grid.best_params_\n",
    "            best_idx = idx\n",
    "\n",
    "    print(f\"Best score: {round(best_score, 4)} on dataset idx {best_idx}.\")\n",
    "    print(best_params)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 252 candidates, totalling 756 fits\n",
      "0.8696 -> 0.8406\n",
      "\n",
      "Fitting 3 folds for each of 252 candidates, totalling 756 fits\n",
      "0.8801 -> 0.8188\n",
      "\n",
      "Fitting 3 folds for each of 252 candidates, totalling 756 fits\n",
      "0.8765 -> 0.8551\n",
      "\n",
      "Fitting 3 folds for each of 252 candidates, totalling 756 fits\n",
      "0.8884 -> 0.8333\n",
      "\n",
      "Best score: 0.8551 on dataset idx 2.\n",
      "{'model__leaf_size': 1, 'model__n_neighbors': 25, 'model__weights': 'uniform', 'shrink__threshold': 0.15}\n"
     ]
    }
   ],
   "source": [
    "# KNeighborsClassifier performs pretty well, lets fine-tune its parameters\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    (\"shrink\", Shrinker()),\n",
    "    (\"model\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    \"shrink__threshold\": [0.25, 0.2, 0.15, 0.1, 0.05, 0.025, 0.],\n",
    "    \"model__n_neighbors\": [5, 10, 20, 25, 30, 35],\n",
    "    \"model__weights\": [\"uniform\", \"distance\"],\n",
    "    \"model__leaf_size\": [1, 2, 3],\n",
    "}\n",
    "\n",
    "knn = search(model_pipeline, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "0.8786 -> 0.8406\n",
      "\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "0.8897 -> 0.8406\n",
      "\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "0.8907 -> 0.8406\n",
      "\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "0.9013 -> 0.8406\n",
      "\n",
      "Best score: 0.8406 on dataset idx 0.\n",
      "{'model__criterion': 'entropy', 'model__max_depth': 25, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 250, 'shrink__threshold': 0.15}\n"
     ]
    }
   ],
   "source": [
    "# let's check Random Forest as well\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    (\"shrink\", Shrinker()),\n",
    "    (\"model\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    \"shrink__threshold\": [0.15, 0.1, 0.05],\n",
    "    \"model__n_estimators\": [250, 500],\n",
    "    \"model__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"model__max_depth\": [5, 10, 25],\n",
    "    \"model__min_samples_leaf\": [2, 5],\n",
    "    \"model__min_samples_split\": [5, 10],\n",
    "}\n",
    "\n",
    "rfc1 = search(model_pipeline, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "0.8786 -> 0.8551\n",
      "\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "0.8917 -> 0.8551\n",
      "\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "0.8907 -> 0.8188\n",
      "\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      " 0.897 -> 0.8478\n",
      "\n",
      "Best score: 0.8551 on dataset idx 0.\n",
      "{'model__max_depth': 8, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 250, 'shrink__threshold': 0.025}\n"
     ]
    }
   ],
   "source": [
    "# let's go a little bit further\n",
    "\n",
    "parameters = {\n",
    "    \"shrink__threshold\": [0.075, 0.05, 0.025],\n",
    "    \"model__n_estimators\": [150, 200, 250],\n",
    "    \"model__max_depth\": [8, 10, 12],\n",
    "    \"model__min_samples_leaf\": [2, 3, 5],\n",
    "    \"model__min_samples_split\": [3, 5, 7],\n",
    "}\n",
    "\n",
    "rfc2 = search(model_pipeline, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "0.8804 -> 0.8623\n",
      "\n",
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "0.8917 -> 0.8623\n",
      "\n",
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "0.8886 -> 0.8551\n",
      "\n",
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      " 0.897 -> 0.8623\n",
      "\n",
      "Best score: 0.8623 on dataset idx 0.\n",
      "{'max_depth': 17, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# and further this time withoyt shrinking\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": [400, 500, 600],\n",
    "    \"max_depth\": [15, 17, 19],\n",
    "    \"min_samples_split\": [5, 7, 9],\n",
    "    \"min_samples_leaf\": [1, 2, 3]\n",
    "}\n",
    "\n",
    "rfc3 = search(model, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      "0.8714 -> 0.8261\n",
      "\n",
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      " 0.882 -> 0.8406\n",
      "\n",
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      "0.8805 -> 0.8261\n",
      "\n",
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      "0.8927 -> 0.8261\n",
      "\n",
      "Best score: 0.8406 on dataset idx 1.\n",
      "{'model__C': 1.0, 'model__degree': 3, 'model__gamma': 'scale', 'model__kernel': 'rbf', 'shrink__threshold': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# lets check SVC as well\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    (\"shrink\", Shrinker()),\n",
    "    (\"model\", SVC())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    \"shrink__threshold\": [0.1, 0.075, 0.05, 0.025, 0.],\n",
    "    \"model__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"model__degree\": [3, 5],\n",
    "    \"model__C\": [0.5, 1., 1.5, 2, 3],\n",
    "    \"model__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "svc = search(model_pipeline, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                             -> accuracy   -> precision  -> recall     -> f1        \n",
      "<class 'sklearn.pipeline.Pipeline'>                          -> 0.8551     -> 0.8529     -> 0.8529     -> 0.8529    \n",
      "<class 'sklearn.pipeline.Pipeline'>                          -> 0.8406     -> 0.8382     -> 0.8382     -> 0.8382    \n",
      "<class 'sklearn.pipeline.Pipeline'>                          -> 0.8551     -> 0.8243     -> 0.8971     -> 0.8592    \n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>    -> 0.8623     -> 0.8356     -> 0.8971     -> 0.8652    \n",
      "<class 'sklearn.pipeline.Pipeline'>                          -> 0.8406     -> 0.8382     -> 0.8382     -> 0.8382    \n"
     ]
    }
   ],
   "source": [
    "# lets check our model's scores\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def print_scores(models, X, y):\n",
    "    print(f\"{'':60} -> {'accuracy':10} -> {'precision':10} -> {'recall':10} -> {'f1':10}\")\n",
    "    \n",
    "    for model in models:\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "        accuracy = round(accuracy_score(y, y_pred), 4)\n",
    "        precision = round(precision_score(y, y_pred), 4)\n",
    "        recall = round(recall_score(y, y_pred), 4)\n",
    "        f1 = round(f1_score(y, y_pred), 4)\n",
    "\n",
    "        print(f\"{str(model.__class__):60} -> {accuracy:<10} -> {precision:<10} -> {recall:<10} -> {f1:<10}\")\n",
    "\n",
    "print_scores([knn, rfc1, rfc2, rfc3, svc], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;knn&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;shrink&#x27;,\n",
       "                                               Shrinker(threshold=0.15)),\n",
       "                                              (&#x27;model&#x27;,\n",
       "                                               KNeighborsClassifier(leaf_size=1,\n",
       "                                                                    n_neighbors=25))])),\n",
       "                             (&#x27;rfc1&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;shrink&#x27;,\n",
       "                                               Shrinker(threshold=0.15)),\n",
       "                                              (&#x27;model&#x27;,\n",
       "                                               RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                                      max_depth=25,\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=5,\n",
       "                                                                      n_estimators=250))])),\n",
       "                             (&#x27;rfc2&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;shrink&#x27;,\n",
       "                                               Shrinker(threshold=0.025)),\n",
       "                                              (&#x27;model&#x27;,\n",
       "                                               RandomForestClassifier(max_depth=8,\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=5,\n",
       "                                                                      n_estimators=250))])),\n",
       "                             (&#x27;rfc3&#x27;,\n",
       "                              RandomForestClassifier(max_depth=17,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     n_estimators=400,\n",
       "                                                     n_jobs=-1)),\n",
       "                             (&#x27;svc&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;shrink&#x27;,\n",
       "                                               Shrinker(threshold=0.0)),\n",
       "                                              (&#x27;model&#x27;, SVC())]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;knn&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;shrink&#x27;,\n",
       "                                               Shrinker(threshold=0.15)),\n",
       "                                              (&#x27;model&#x27;,\n",
       "                                               KNeighborsClassifier(leaf_size=1,\n",
       "                                                                    n_neighbors=25))])),\n",
       "                             (&#x27;rfc1&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;shrink&#x27;,\n",
       "                                               Shrinker(threshold=0.15)),\n",
       "                                              (&#x27;model&#x27;,\n",
       "                                               RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                                      max_depth=25,\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=5,\n",
       "                                                                      n_estimators=250))])),\n",
       "                             (&#x27;rfc2&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;shrink&#x27;,\n",
       "                                               Shrinker(threshold=0.025)),\n",
       "                                              (&#x27;model&#x27;,\n",
       "                                               RandomForestClassifier(max_depth=8,\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=5,\n",
       "                                                                      n_estimators=250))])),\n",
       "                             (&#x27;rfc3&#x27;,\n",
       "                              RandomForestClassifier(max_depth=17,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     n_estimators=400,\n",
       "                                                     n_jobs=-1)),\n",
       "                             (&#x27;svc&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;shrink&#x27;,\n",
       "                                               Shrinker(threshold=0.0)),\n",
       "                                              (&#x27;model&#x27;, SVC())]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Shrinker</label><div class=\"sk-toggleable__content\"><pre>Shrinker(threshold=0.15)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(leaf_size=1, n_neighbors=25)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rfc1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Shrinker</label><div class=\"sk-toggleable__content\"><pre>Shrinker(threshold=0.15)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=25, min_samples_leaf=2,\n",
       "                       min_samples_split=5, n_estimators=250)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rfc2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Shrinker</label><div class=\"sk-toggleable__content\"><pre>Shrinker(threshold=0.025)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, min_samples_leaf=2, min_samples_split=5,\n",
       "                       n_estimators=250)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rfc3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=17, min_samples_split=5, n_estimators=400,\n",
       "                       n_jobs=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Shrinker</label><div class=\"sk-toggleable__content\"><pre>Shrinker(threshold=0.0)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('knn',\n",
       "                              Pipeline(steps=[('shrink',\n",
       "                                               Shrinker(threshold=0.15)),\n",
       "                                              ('model',\n",
       "                                               KNeighborsClassifier(leaf_size=1,\n",
       "                                                                    n_neighbors=25))])),\n",
       "                             ('rfc1',\n",
       "                              Pipeline(steps=[('shrink',\n",
       "                                               Shrinker(threshold=0.15)),\n",
       "                                              ('model',\n",
       "                                               RandomForestClassifier(criterion='entropy',\n",
       "                                                                      max_depth=25,\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=5,\n",
       "                                                                      n_estimators=250))])),\n",
       "                             ('rfc2',\n",
       "                              Pipeline(steps=[('shrink',\n",
       "                                               Shrinker(threshold=0.025)),\n",
       "                                              ('model',\n",
       "                                               RandomForestClassifier(max_depth=8,\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=5,\n",
       "                                                                      n_estimators=250))])),\n",
       "                             ('rfc3',\n",
       "                              RandomForestClassifier(max_depth=17,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     n_estimators=400,\n",
       "                                                     n_jobs=-1)),\n",
       "                             ('svc',\n",
       "                              Pipeline(steps=[('shrink',\n",
       "                                               Shrinker(threshold=0.0)),\n",
       "                                              ('model', SVC())]))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all these classfiers are pretty close together. In banking industry\n",
    "# probably recall is more important than precision. Let's try to evaluate\n",
    "# ensamble of all upper models\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimators = [\n",
    "    (\"knn\", knn),\n",
    "    (\"rfc1\", rfc1),\n",
    "    (\"rfc2\", rfc2),\n",
    "    (\"rfc3\", rfc3),\n",
    "    (\"svc\", svc),\n",
    "]\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                             -> accuracy   -> precision  -> recall     -> f1        \n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'>          -> 0.8478     -> 0.8406     -> 0.8529     -> 0.8467    \n"
     ]
    }
   ],
   "source": [
    "print_scores([ensemble], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 1788229358 scored 0.8623\n",
      "Seed 1848221597 scored 0.8551\n",
      "Seed 4262162904 scored 0.8551\n",
      "Seed 973723101 scored 0.8406\n",
      "Seed 3326910681 scored 0.8551\n",
      "Seed 1926451121 scored 0.8551\n",
      "Seed 1217183639 scored 0.8623\n",
      "Seed 978639232 scored 0.8551\n",
      "Seed 781319044 scored 0.8478\n",
      "Seed 1856117230 scored 0.8478\n",
      "Seed 1038101335 scored 0.8551\n",
      "Seed 2082572263 scored 0.8478\n",
      "Seed 621948243 scored 0.8551\n",
      "Seed 3502396020 scored 0.8551\n",
      "Seed 3665212353 scored 0.8696\n",
      "Seed 3000823579 scored 0.8406\n",
      "Seed 20604202 scored 0.8478\n",
      "Seed 3812031052 scored 0.8478\n",
      "Seed 2318103540 scored 0.8551\n",
      "Seed 1963773201 scored 0.8623\n",
      "Seed 3885743564 scored 0.8406\n",
      "Seed 1797743865 scored 0.8551\n",
      "Seed 2079931911 scored 0.8406\n",
      "Seed 2736374847 scored 0.8623\n",
      "Seed 599195974 scored 0.8696\n",
      "Seed 208387935 scored 0.8551\n",
      "Seed 1613864593 scored 0.8551\n",
      "Seed 465983671 scored 0.8478\n",
      "Seed 843174651 scored 0.8623\n",
      "Seed 2689992645 scored 0.8478\n",
      "Seed 2637227396 scored 0.8406\n",
      "Seed 3670331021 scored 0.8478\n",
      "Seed 1480966104 scored 0.8551\n",
      "Seed 826749810 scored 0.8551\n",
      "Seed 831916648 scored 0.8623\n",
      "Seed 2058028977 scored 0.8623\n",
      "Seed 2738698071 scored 0.8551\n",
      "Seed 3862054377 scored 0.8696\n",
      "Seed 2058658201 scored 0.8623\n",
      "Seed 3719438336 scored 0.8478\n",
      "Seed 990848538 scored 0.8551\n",
      "Seed 2631213891 scored 0.8551\n",
      "Seed 1444873580 scored 0.8696\n",
      "Seed 470007844 scored 0.8551\n",
      "Seed 2620483041 scored 0.8551\n",
      "Seed 78383643 scored 0.8551\n",
      "Seed 4290678778 scored 0.8551\n",
      "Seed 4160338548 scored 0.8551\n",
      "Seed 1932866461 scored 0.8551\n",
      "Seed 3939101040 scored 0.8551\n",
      "Seed 2010077985 scored 0.8623\n",
      "Seed 780995029 scored 0.8478\n",
      "Seed 1623066337 scored 0.8478\n",
      "Seed 2963086568 scored 0.8478\n",
      "Seed 3438690290 scored 0.8406\n",
      "Seed 3327336189 scored 0.8551\n",
      "Seed 1891187580 scored 0.8478\n",
      "Seed 4259352474 scored 0.8551\n",
      "Seed 1028075113 scored 0.8623\n",
      "Seed 252340262 scored 0.8551\n",
      "Seed 1471557222 scored 0.8623\n",
      "Seed 465479695 scored 0.8696\n",
      "Seed 87143377 scored 0.8623\n",
      "Seed 1293791134 scored 0.8406\n",
      "Seed 3499644020 scored 0.8623\n",
      "Seed 1737691559 scored 0.8478\n",
      "Seed 2042385484 scored 0.8551\n",
      "Seed 2749014589 scored 0.8551\n",
      "Seed 3507526864 scored 0.8551\n",
      "Seed 2702559511 scored 0.8623\n",
      "Seed 4245510349 scored 0.8623\n",
      "Seed 1267355076 scored 0.8478\n",
      "Seed 1081143297 scored 0.8478\n",
      "Seed 1997535295 scored 0.8551\n",
      "Seed 2858225156 scored 0.8551\n",
      "Seed 2818840284 scored 0.8551\n",
      "Seed 4206264303 scored 0.8696\n",
      "Seed 2743555033 scored 0.8478\n",
      "Seed 2320890591 scored 0.8551\n",
      "Seed 109689267 scored 0.8478\n",
      "Seed 644415357 scored 0.8623\n",
      "Seed 743525202 scored 0.8623\n",
      "Seed 2963625047 scored 0.8551\n",
      "Seed 4103492036 scored 0.8551\n",
      "Seed 892009652 scored 0.8551\n",
      "Seed 1025702423 scored 0.8768\n",
      "Seed 374521344 scored 0.8551\n",
      "Seed 1795035685 scored 0.8551\n",
      "Seed 1613881471 scored 0.8623\n",
      "Seed 3359499858 scored 0.8623\n",
      "Seed 477442436 scored 0.8551\n",
      "Seed 4031235619 scored 0.8551\n",
      "Seed 2552317518 scored 0.8696\n",
      "Seed 3006864626 scored 0.8551\n",
      "Seed 2814436992 scored 0.8623\n",
      "Seed 1311746977 scored 0.8623\n",
      "Seed 2129585032 scored 0.8551\n",
      "Seed 4175213889 scored 0.8551\n",
      "Seed 824240974 scored 0.8551\n",
      "Seed 575469262 scored 0.8696\n",
      "Best score found: 0.8768115942028986\n"
     ]
    }
   ],
   "source": [
    "# scince we have light model and small dataset.\n",
    "# we can search for better models via changing seeds\n",
    "\n",
    "import random\n",
    "\n",
    "# check based on accuracy\n",
    "best_score = rfc3.score(X_test, y_test)\n",
    "params = rfc3.get_params()\n",
    "\n",
    "for seed in [random.randint(0, 2**32) for _ in range(100)]:\n",
    "    model = RandomForestClassifier()\n",
    "    params[\"random_state\"] = seed\n",
    "\n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train_small[1], y_train_small[1])\n",
    "    \n",
    "    score = model.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Seed {seed} scored {round(score, 4)}\")\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        rfc3 = model\n",
    "\n",
    "print(f\"Best score found: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = rfc3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "import pickle\n",
    "\n",
    "MODEL_NAME = \"final_model.pkl\"\n",
    "\n",
    "with open(MODEL_NAME, 'wb') as f:\n",
    "    pickle.dump(final_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets pack all the things together\n",
    "\n",
    "def predict(df, supervised=False):\n",
    "    with open(MODEL_NAME, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    if supervised:\n",
    "        assert len(df.shape) == 2 and df.shape[1] == 16\n",
    "        X, y = df.to_numpy()[:, :-1], df.to_numpy()[:, -1]\n",
    "        y = y_preparation_pipeline.transform(y.reshape(-1, 1)).ravel()\n",
    "    else:\n",
    "        assert len(df.shape == 2) and df.shape[1] == 15\n",
    "        X = df.to_numpy()\n",
    "\n",
    "    X = X_preparation_pipeline.transform(X)\n",
    "\n",
    "    if supervised:\n",
    "        print_scores([model], X, y)\n",
    "\n",
    "    return model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                             -> accuracy   -> precision  -> recall     -> f1        \n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>    -> 0.9507     -> 0.944      -> 0.9687     -> 0.9562    \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(get_df(\"data.data\"), header=None, na_values=\"?\")\n",
    "\n",
    "y_pred = predict(df, supervised=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
